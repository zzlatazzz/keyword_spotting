{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhrn5O-qUYZ"
      },
      "source": [
        "# Import and misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "meO-Mp9jiAFC"
      },
      "outputs": [],
      "source": [
        "# Instal latest torch and torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bbUpoArCqUYa"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union, List, Callable, Optional\n",
        "from tqdm import tqdm\n",
        "from itertools import islice\n",
        "import pathlib\n",
        "import dataclasses\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchaudio\n",
        "from IPython import display as display_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812GwLfqqUYf"
      },
      "source": [
        "# Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8PdhApeEh9pH"
      },
      "outputs": [],
      "source": [
        "@dataclasses.dataclass\n",
        "class TaskConfig:\n",
        "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 3e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    num_epochs: int = 20\n",
        "    n_mels: int = 40\n",
        "    cnn_out_channels: int = 8\n",
        "    kernel_size: Tuple[int, int] = (5, 20)\n",
        "    stride: Tuple[int, int] = (2, 8)\n",
        "    hidden_size: int = 64\n",
        "    gru_num_layers: int = 2\n",
        "    bidirectional: bool = False\n",
        "    num_classes: int = 2\n",
        "    sample_rate: int = 16000\n",
        "    device: torch.device = torch.device(\n",
        "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA1gPmE1h9pI"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2N8zcx9MF1X",
        "outputId": "85ca4eef-41fc-4e32-8b78-eb98624784d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-31 06:20:43--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.253.115.128, 2607:f8b0:4004:c06::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.253.115.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G   229MB/s    in 6.4s    \n",
            "\n",
            "2022-10-31 06:20:50 (223 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
        "!mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "12wBTK0mNUsG"
      },
      "outputs": [],
      "source": [
        "class SpeechCommandDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        transform: Optional[Callable] = None,\n",
        "        path2dir: str = None,\n",
        "        keywords: Union[str, List[str]] = None,\n",
        "        csv: Optional[pd.DataFrame] = None\n",
        "    ):        \n",
        "        self.transform = transform\n",
        "\n",
        "        if csv is None:\n",
        "            path2dir = pathlib.Path(path2dir)\n",
        "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
        "            \n",
        "            all_keywords = [\n",
        "                p.stem for p in path2dir.glob('*')\n",
        "                if p.is_dir() and not p.stem.startswith('_')\n",
        "            ]\n",
        "\n",
        "            triplets = []\n",
        "            for keyword in all_keywords:\n",
        "                paths = (path2dir / keyword).rglob('*.wav')\n",
        "                if keyword in keywords:\n",
        "                    for path2wav in paths:\n",
        "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
        "                else:\n",
        "                    for path2wav in paths:\n",
        "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
        "            \n",
        "            self.csv = pd.DataFrame(\n",
        "                triplets,\n",
        "                columns=['path', 'keyword', 'label']\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.csv = csv\n",
        "    \n",
        "    def __getitem__(self, index: int):\n",
        "        instance = self.csv.iloc[index]\n",
        "\n",
        "        path2wav = instance['path']\n",
        "        wav, sr = torchaudio.load(path2wav)\n",
        "        wav = wav.sum(dim=0)\n",
        "        \n",
        "        if self.transform:\n",
        "            wav = self.transform(wav)\n",
        "\n",
        "        return {\n",
        "            'wav': wav,\n",
        "            'keywors': instance['keyword'],\n",
        "            'label': instance['label']\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-1rVkT81Pk90"
      },
      "outputs": [],
      "source": [
        "dataset = SpeechCommandDataset(\n",
        "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "DFwhAXdfQLIA",
        "outputId": "4d3c0bd9-5f47-4fb6-8bf9-d5f5299d3c65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              path keyword  label\n",
              "4323    speech_commands/bird/5de8f2f0_nohash_0.wav    bird      0\n",
              "64388  speech_commands/house/a759efbc_nohash_2.wav   house      0\n",
              "22750    speech_commands/six/83f9c4ab_nohash_0.wav     six      0\n",
              "50342    speech_commands/yes/25132942_nohash_1.wav     yes      0\n",
              "17880   speech_commands/stop/f19c1390_nohash_4.wav    stop      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a84264f-a6f3-4c61-86f0-daf249c60fe3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>keyword</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4323</th>\n",
              "      <td>speech_commands/bird/5de8f2f0_nohash_0.wav</td>\n",
              "      <td>bird</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64388</th>\n",
              "      <td>speech_commands/house/a759efbc_nohash_2.wav</td>\n",
              "      <td>house</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22750</th>\n",
              "      <td>speech_commands/six/83f9c4ab_nohash_0.wav</td>\n",
              "      <td>six</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50342</th>\n",
              "      <td>speech_commands/yes/25132942_nohash_1.wav</td>\n",
              "      <td>yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17880</th>\n",
              "      <td>speech_commands/stop/f19c1390_nohash_4.wav</td>\n",
              "      <td>stop</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a84264f-a6f3-4c61-86f0-daf249c60fe3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a84264f-a6f3-4c61-86f0-daf249c60fe3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a84264f-a6f3-4c61-86f0-daf249c60fe3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset.csv.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUxfDJw1qUYi"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dkmkxPWQqUYe"
      },
      "outputs": [],
      "source": [
        "class AugsCreation:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.background_noises = [\n",
        "            'speech_commands/_background_noise_/white_noise.wav',\n",
        "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
        "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
        "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
        "            'speech_commands/_background_noise_/pink_noise.wav',\n",
        "            'speech_commands/_background_noise_/running_tap.wav'\n",
        "        ]\n",
        "\n",
        "        self.noises = [\n",
        "            torchaudio.load(p)[0].squeeze()\n",
        "            for p in self.background_noises\n",
        "        ]\n",
        "\n",
        "    def add_rand_noise(self, audio):\n",
        "\n",
        "        # randomly choose noise\n",
        "        noise_num = torch.randint(low=0, high=len(\n",
        "            self.background_noises), size=(1,)).item()\n",
        "        noise = self.noises[noise_num]\n",
        "\n",
        "        noise_level = torch.Tensor([1])  # [0, 40]\n",
        "\n",
        "        noise_energy = torch.norm(noise)\n",
        "        audio_energy = torch.norm(audio)\n",
        "        alpha = (audio_energy / noise_energy) * \\\n",
        "            torch.pow(10, -noise_level / 20)\n",
        "\n",
        "        start = torch.randint(\n",
        "            low=0,\n",
        "            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n",
        "            size=(1,)\n",
        "        ).item()\n",
        "        noise_sample = noise[start: start + audio.size(0)]\n",
        "\n",
        "        audio_new = audio + alpha * noise_sample\n",
        "        audio_new.clamp_(-1, 1)\n",
        "        return audio_new\n",
        "\n",
        "    def __call__(self, wav):\n",
        "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
        "        augs = [\n",
        "            lambda x: x,\n",
        "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
        "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
        "            lambda x: self.add_rand_noise(x)\n",
        "        ]\n",
        "\n",
        "        return augs[aug_num](wav)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ClWThxyYh9pM"
      },
      "outputs": [],
      "source": [
        "indexes = torch.randperm(len(dataset))\n",
        "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
        "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
        "\n",
        "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
        "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PDPLht5fqUYe"
      },
      "outputs": [],
      "source": [
        "# Sample is a dict of utt, word and label\n",
        "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
        "val_set = SpeechCommandDataset(csv=val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmrJd8WIhkLP",
        "outputId": "29699797-ca42-47e8-ca0e-01ea79fec368"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'wav': tensor([-0.0152, -0.0155, -0.0149,  ...,  0.0126, -0.0022, -0.0026]),\n",
              " 'keywors': 'five',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_set[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbPDqd6qUYj"
      },
      "source": [
        "### Sampler for oversampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rfnjRKo2qUYj"
      },
      "outputs": [],
      "source": [
        "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
        "\n",
        "def get_sampler(target):\n",
        "    class_sample_count = np.array(\n",
        "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in target])\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    samples_weigth = samples_weight.float()\n",
        "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "    return sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UM8gLmHeqUYj"
      },
      "outputs": [],
      "source": [
        "train_sampler = get_sampler(train_set.csv['label'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lyBqbxp0h9pO"
      },
      "outputs": [],
      "source": [
        "class Collator:\n",
        "    \n",
        "    def __call__(self, data):\n",
        "        wavs = []\n",
        "        labels = []    \n",
        "\n",
        "        for el in data:\n",
        "            wavs.append(el['wav'])\n",
        "            labels.append(el['label'])\n",
        "\n",
        "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
        "        wavs = pad_sequence(wavs, batch_first=True)    \n",
        "        labels = torch.Tensor(labels).long()\n",
        "        return wavs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8G9xPRVqUYk"
      },
      "source": [
        "###  Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6wGBMcQiqUYk"
      },
      "outputs": [],
      "source": [
        "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
        "                          shuffle=False, collate_fn=Collator(),\n",
        "                          sampler=train_sampler,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
        "                        shuffle=False, collate_fn=Collator(),\n",
        "                        num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTlsn6cpqUYk"
      },
      "source": [
        "### Creating MelSpecs on GPU for speeeed: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pRXMt6it56fW"
      },
      "outputs": [],
      "source": [
        "class LogMelspec:\n",
        "\n",
        "    def __init__(self, is_train, config):\n",
        "        # with augmentations\n",
        "        if is_train:\n",
        "            self.melspec = nn.Sequential(\n",
        "                torchaudio.transforms.MelSpectrogram(\n",
        "                    sample_rate=config.sample_rate,\n",
        "                    n_fft=400,\n",
        "                    win_length=400,\n",
        "                    hop_length=160,\n",
        "                    n_mels=config.n_mels\n",
        "                ),\n",
        "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
        "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
        "            ).to(config.device)\n",
        "\n",
        "        # no augmentations\n",
        "        else:\n",
        "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
        "                sample_rate=config.sample_rate,\n",
        "                n_fft=400,\n",
        "                win_length=400,\n",
        "                hop_length=160,\n",
        "                n_mels=config.n_mels\n",
        "            ).to(config.device)\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # already on device\n",
        "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pqkz4_gn8BiF"
      },
      "outputs": [],
      "source": [
        "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
        "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPMgfwowi3X-"
      },
      "source": [
        "# Streaming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.energy = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        energy = self.energy(input)\n",
        "        alpha = torch.softmax(energy, dim=-2)\n",
        "        return (input * alpha).sum(dim=-2)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TaskConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1, out_channels=config.cnn_out_channels,\n",
        "                kernel_size=config.kernel_size, stride=config.stride\n",
        "            ),\n",
        "            nn.Flatten(start_dim=1, end_dim=2),\n",
        "        )\n",
        "\n",
        "        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n",
        "            config.stride[0] + 1\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.conv_out_frequency * config.cnn_out_channels,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.gru_num_layers,\n",
        "            dropout=0.1,\n",
        "            bidirectional=config.bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.attention = Attention(config.hidden_size)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        input = input.unsqueeze(dim=1)\n",
        "        conv_output = self.conv(input).transpose(-1, -2)\n",
        "        gru_output, _ = self.gru(conv_output)\n",
        "        contex_vector = self.attention(gru_output)\n",
        "        output = self.classifier(contex_vector)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "g9QI7Kn1wKv6"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PpyvKwp0k3IU"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StreamCRNN(CRNN):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "    \n",
        "    def stream_forward(self, input, hidden=None):\n",
        "        input = input.unsqueeze(dim=1)\n",
        "        conv_output = self.conv(input).transpose(-1, -2)\n",
        "        gru_output, hidden = self.gru(conv_output, hidden) if hidden is not None else self.gru(conv_output)\n",
        "        contex_vector = self.attention(gru_output)\n",
        "        output = self.classifier(contex_vector)\n",
        "        return output, hidden\n",
        "\n",
        "    \n",
        "class Streaming():\n",
        "    def __init__(self,  max_window_length=40, streaming_step_size=2):\n",
        "        self.max_window_length = max_window_length\n",
        "        self.streaming_step_size = streaming_step_size\n",
        "        \n",
        "    def stream(self, model, input):\n",
        "        model.eval()\n",
        "        kernel_width = model.conv[0].kernel_size[1]\n",
        "        stride = model.conv[0].stride[-1]\n",
        "        max_window_length = self.max_window_length - (self.max_window_length - kernel_width) % stride\n",
        "        hidden = None\n",
        "        \n",
        "        output, hidden = model.stream_forward(input[:,:,:max_window_length])\n",
        "        result = output.unsqueeze(1)\n",
        "\n",
        "        for i in range(max_window_length, input.shape[-1], self.streaming_step_size):\n",
        "            output, hidden = model.stream_forward(input[:,:, i - max_window_length + 1 : i + 1], hidden=hidden)\n",
        "            output = output.unsqueeze(1)\n",
        "            result = torch.cat((result, output[:, -1:]), dim=1)\n",
        "        probs = F.softmax(result, dim=-1)[0].detach().numpy()\n",
        "        clear_output()\n",
        "        plt.plot(list(range(self.max_window_length // 2, probs.shape[0] * self.streaming_step_size + self.max_window_length // 2, self.streaming_step_size)), probs[:,1])\n",
        "        return result"
      ],
      "metadata": {
        "id": "JUF974hhwBDG"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading teacher model\n",
        "\n",
        "tconfig = TaskConfig()\n",
        "teacher = StreamCRNN(tconfig)\n",
        "teacher.load_state_dict(torch.load('teacher_model.pt', map_location='cpu'))\n",
        "teacher.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJBVhsu1tIAc",
        "outputId": "7e2f2552-d80f-44dc-d03a-ca47c1744f28"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StreamCRNN(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
              "    (1): Flatten(start_dim=1, end_dim=2)\n",
              "  )\n",
              "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (attention): Attention(\n",
              "    (energy): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, t in enumerate(train_set):\n",
        "    if t['label'] == 1:\n",
        "        print(i)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLqKKfJytyGa",
        "outputId": "40f685fc-29c6-42c0-cecd-6a0de70ae000"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "F9yRdNfyK9vE"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_all(112)\n",
        "\n",
        "st = Streaming(max_window_length = 40, streaming_step_size=2)\n",
        "\n",
        "audio = torch.cat([train_set[i]['wav'] for i in range(15)] + [train_set[92]['wav']] + [train_set[i]['wav'] for i in range(15, 30)])\n",
        "mel = melspec_train(audio.unsqueeze(0).to(tconfig.device))\n",
        "result = st.stream(teacher, mel) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9o706a-huL-O",
        "outputId": "0a946dc0-be42-4709-d793-e7e932d8293f"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}