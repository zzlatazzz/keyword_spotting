{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "# Import and misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "meO-Mp9jiAFC"
   },
   "outputs": [],
   "source": [
    "# Instal latest torch and torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bbUpoArCqUYa"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List, Callable, Optional\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import pathlib\n",
    "import dataclasses\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "812GwLfqqUYf"
   },
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8PdhApeEh9pH"
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TaskConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    num_epochs: int = 20\n",
    "    n_mels: int = 40\n",
    "    cnn_out_channels: int = 8\n",
    "    kernel_size: Tuple[int, int] = (5, 20)\n",
    "    stride: Tuple[int, int] = (2, 8)\n",
    "    hidden_size: int = 64\n",
    "    gru_num_layers: int = 2\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    sample_rate: int = 16000\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA1gPmE1h9pI"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2N8zcx9MF1X",
    "outputId": "2f95cd5f-9b98-4d53-ed8d-927d9d5d06de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-01 22:15:21--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.142.128, 2607:f8b0:400e:c08::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.142.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1489096277 (1.4G) [application/gzip]\n",
      "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
      "\n",
      "speech_commands_v0. 100%[===================>]   1.39G   131MB/s    in 8.7s    \n",
      "\n",
      "2022-11-01 22:15:30 (163 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
      "\n",
      "mkdir: cannot create directory ‘speech_commands’: File exists\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
    "!mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "12wBTK0mNUsG"
   },
   "outputs": [],
   "source": [
    "class SpeechCommandDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transform: Optional[Callable] = None,\n",
    "        path2dir: str = None,\n",
    "        keywords: Union[str, List[str]] = None,\n",
    "        csv: Optional[pd.DataFrame] = None\n",
    "    ):        \n",
    "        self.transform = transform\n",
    "\n",
    "        if csv is None:\n",
    "            path2dir = pathlib.Path(path2dir)\n",
    "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
    "            \n",
    "            all_keywords = [\n",
    "                p.stem for p in path2dir.glob('*')\n",
    "                if p.is_dir() and not p.stem.startswith('_')\n",
    "            ]\n",
    "\n",
    "            triplets = []\n",
    "            for keyword in all_keywords:\n",
    "                paths = (path2dir / keyword).rglob('*.wav')\n",
    "                if keyword in keywords:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
    "                else:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
    "            \n",
    "            self.csv = pd.DataFrame(\n",
    "                triplets,\n",
    "                columns=['path', 'keyword', 'label']\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.csv = csv\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        instance = self.csv.iloc[index]\n",
    "\n",
    "        path2wav = instance['path']\n",
    "        wav, sr = torchaudio.load(path2wav)\n",
    "        wav = wav.sum(dim=0)\n",
    "        \n",
    "        if self.transform:\n",
    "            wav = self.transform(wav)\n",
    "\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'keywors': instance['keyword'],\n",
    "            'label': instance['label']\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-1rVkT81Pk90"
   },
   "outputs": [],
   "source": [
    "dataset = SpeechCommandDataset(\n",
    "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "DFwhAXdfQLIA",
    "outputId": "52657166-a3a4-40d8-c79b-31454d1a0a63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d18fb56e-e619-4f9d-b53f-3b37fbca3937\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>speech_commands/sheila/7192fddc_nohash_0.wav</td>\n",
       "      <td>sheila</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41377</th>\n",
       "      <td>speech_commands/down/36050ef3_nohash_1.wav</td>\n",
       "      <td>down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44430</th>\n",
       "      <td>speech_commands/nine/aeb99b1c_nohash_0.wav</td>\n",
       "      <td>nine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59587</th>\n",
       "      <td>speech_commands/house/21e8c417_nohash_0.wav</td>\n",
       "      <td>house</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25211</th>\n",
       "      <td>speech_commands/go/b87bdb22_nohash_3.wav</td>\n",
       "      <td>go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d18fb56e-e619-4f9d-b53f-3b37fbca3937')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d18fb56e-e619-4f9d-b53f-3b37fbca3937 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d18fb56e-e619-4f9d-b53f-3b37fbca3937');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               path keyword  label\n",
       "3828   speech_commands/sheila/7192fddc_nohash_0.wav  sheila      1\n",
       "41377    speech_commands/down/36050ef3_nohash_1.wav    down      0\n",
       "44430    speech_commands/nine/aeb99b1c_nohash_0.wav    nine      0\n",
       "59587   speech_commands/house/21e8c417_nohash_0.wav   house      0\n",
       "25211      speech_commands/go/b87bdb22_nohash_3.wav      go      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.csv.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "class AugsCreation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "            'speech_commands/_background_noise_/white_noise.wav',\n",
    "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "            'speech_commands/_background_noise_/pink_noise.wav',\n",
    "            'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "        self.noises = [\n",
    "            torchaudio.load(p)[0].squeeze()\n",
    "            for p in self.background_noises\n",
    "        ]\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "\n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(\n",
    "            self.background_noises), size=(1,)).item()\n",
    "        noise = self.noises[noise_num]\n",
    "\n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * \\\n",
    "            torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(\n",
    "            low=0,\n",
    "            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n",
    "            size=(1,)\n",
    "        ).item()\n",
    "        noise_sample = noise[start: start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "\n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ClWThxyYh9pM"
   },
   "outputs": [],
   "source": [
    "indexes = torch.randperm(len(dataset))\n",
    "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
    "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
    "\n",
    "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
    "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PDPLht5fqUYe"
   },
   "outputs": [],
   "source": [
    "# Sample is a dict of utt, word and label\n",
    "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
    "val_set = SpeechCommandDataset(csv=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmrJd8WIhkLP",
    "outputId": "59217f05-d6be-4816-a9f0-f02de1fe0940"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wav': tensor([ 0.0124, -0.0154,  0.0038,  ...,  0.0043, -0.0081, -0.0080]),\n",
       " 'keywors': 'stop',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.float()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.csv['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lyBqbxp0h9pO"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        wavs = []\n",
    "        labels = []    \n",
    "\n",
    "        for el in data:\n",
    "            wavs.append(el['wav'])\n",
    "            labels.append(el['label'])\n",
    "\n",
    "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "        wavs = pad_sequence(wavs, batch_first=True)    \n",
    "        labels = torch.Tensor(labels).long()\n",
    "        return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6wGBMcQiqUYk"
   },
   "outputs": [],
   "source": [
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
    "                          shuffle=False, collate_fn=Collator(),\n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
    "                        shuffle=False, collate_fn=Collator(),\n",
    "                        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "class LogMelspec:\n",
    "\n",
    "    def __init__(self, is_train, config):\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate=config.sample_rate,\n",
    "                    n_fft=400,\n",
    "                    win_length=400,\n",
    "                    hop_length=160,\n",
    "                    n_mels=config.n_mels\n",
    "                ),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_fft=400,\n",
    "                win_length=400,\n",
    "                hop_length=160,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # already on device\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
    "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cP_pFIsy5p2",
    "outputId": "fc1d1a13-ea77-4b19-c13b-ff41eba31504"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
       "    (1): Flatten(start_dim=1, end_dim=2)\n",
       "  )\n",
       "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (attention): Attention(\n",
       "    (energy): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        energy = self.energy(input)\n",
    "        alpha = torch.softmax(energy, dim=-2)\n",
    "        return (input * alpha).sum(dim=-2)\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, config: TaskConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=config.cnn_out_channels,\n",
    "                kernel_size=config.kernel_size, stride=config.stride\n",
    "            ),\n",
    "            nn.Flatten(start_dim=1, end_dim=2),\n",
    "        )\n",
    "\n",
    "        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n",
    "            config.stride[0] + 1\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.conv_out_frequency * config.cnn_out_channels,\n",
    "            hidden_size=config.hidden_size,\n",
    "            num_layers=config.gru_num_layers,\n",
    "            dropout=0.1,\n",
    "            bidirectional=config.bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.unsqueeze(dim=1)\n",
    "        conv_output = self.conv(input).transpose(-1, -2)\n",
    "        gru_output, _ = self.gru(conv_output)\n",
    "        contex_vector = self.attention(gru_output)\n",
    "        output = self.classifier(contex_vector)\n",
    "        return output\n",
    "\n",
    "config = TaskConfig()\n",
    "model = CRNN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, log_melspec, device):\n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        output = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSNW-nZCJ4Q0"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PpyvKwp0k3IU"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8sVpHNoocgA",
    "outputId": "23c90d7c-d845-4eca-946c-71e714697387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
      "    (1): Flatten(start_dim=1, end_dim=2)\n",
      "  )\n",
      "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (attention): Attention(\n",
      "    (energy): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "config = TaskConfig()\n",
    "model = CRNN(config).to(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zedXm9dmINAE",
    "outputId": "7306b5fb-3e7d-478a-ecec-9038464854fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70443"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vt2kjqC-IobK"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Uz2hRvhiuzoZ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "\n",
    "    def __init__(self, name: str, verbose=False):\n",
    "        self.name = name\n",
    "        self.verbose = verbose\n",
    "        self.total_time = 0\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.t = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.t = time.time() - self.t\n",
    "        self.total_time += self.t\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"{self.name.capitalize()} | Elapsed time : {self.t:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "32oooz4lqUYo",
    "outputId": "4972d794-d1a7-4a52-fba2-be7ec0de80ea",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher | Elapsed time : 834.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 19\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "seed_all(112)\n",
    "\n",
    "timer = Timer('teacher')\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "    with timer:\n",
    "        train_epoch(model, opt, train_loader, melspec_train, config.device)\n",
    "\n",
    "        au_fa_fr = validation(model, val_loader,\n",
    "                          melspec_val, config.device)\n",
    "        history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"{timer.name.capitalize()} | Elapsed time : {timer.total_time:.2f}\")\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.savefig('dkd.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E05Jy3459RF4",
    "outputId": "026a2f8d-313b-48ae-c18f-fdb341fed3b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'val_metric': [0.000611399119876245,\n",
       "              0.00028338093198472725,\n",
       "              0.00014469512619945843,\n",
       "              9.000852016605896e-05,\n",
       "              7.248183292030445e-05,\n",
       "              4.3950987934961484e-05,\n",
       "              4.2518776515492276e-05,\n",
       "              3.0476265496788634e-05,\n",
       "              2.375083937286446e-05,\n",
       "              3.5936571533515016e-05,\n",
       "              2.324956537605023e-05,\n",
       "              2.4437107344693454e-05,\n",
       "              2.1590587148498395e-05,\n",
       "              2.1894932075135604e-05,\n",
       "              2.5045797197967875e-05,\n",
       "              2.2951187996994146e-05,\n",
       "              2.171590564770195e-05,\n",
       "              1.846359221599061e-05,\n",
       "              1.8940996022480352e-05,\n",
       "              1.690606229731784e-05]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WBkTUHZcVugz"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'teacher_model.pth')\n",
    "torch.save(model.state_dict(), 'teacher_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "SmkSRvg36KdC"
   },
   "outputs": [],
   "source": [
    "tconfig = TaskConfig()\n",
    "teacher = torch.load('teacher_model.pth', map_location=torch.device('cuda:0'))\n",
    "teacher = teacher.to(tconfig.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPMgfwowi3X-"
   },
   "source": [
    "## StudentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "i-7dPBrq6KfH"
   },
   "outputs": [],
   "source": [
    "# Уменьшаем параметры у студента\n",
    "# После решетки указаны старые параметры\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class StudentConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 1e-3 # 3e-4\n",
    "    weight_decay: float = 1e-5 # 1e-5\n",
    "    num_epochs: int = 40 # 20\n",
    "    n_mels: int = 40\n",
    "    cnn_out_channels: int = 2 # 8\n",
    "    kernel_size: Tuple[int, int] = (5, 20) # (5, 20)\n",
    "    stride: Tuple[int, int] = (2, 8) # (2, 8)\n",
    "    hidden_size: int = 22 # 64\n",
    "    gru_num_layers: int = 1 # 2\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    sample_rate: int = 16000\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    T: float = 10\n",
    "    a: float = 0.6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "QzVrM_1w6Kjc"
   },
   "outputs": [],
   "source": [
    "sconfig = StudentConfig()\n",
    "student = CRNN(sconfig).to(sconfig.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIQrRXlskAOY"
   },
   "source": [
    "# Student training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "BvlzuXugsTZp"
   },
   "outputs": [],
   "source": [
    "def dkd_train_epoch(teacher, student, opt, loader, log_melspec, device, T, a):\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        logits_student = student(batch)\n",
    "        with torch.no_grad():\n",
    "            logits_teacher = teacher(batch)\n",
    "\n",
    "        # distillation loss + student loss\n",
    "        probs_student = F.log_softmax(logits_student / T, dim=-1)\n",
    "        probs_teacher = F.log_softmax(logits_teacher / T, dim=-1)\n",
    "        probs = F.softmax(logits_student, dim=-1)\n",
    "        loss = nn.KLDivLoss()(probs_student, probs_teacher) * (T ** 2) * a + F.cross_entropy(logits_student, labels) * (1 - a)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "dKgIipFzwDYF"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def dkd_validation(teacher, student, loader, log_melspec, device, T, a):\n",
    "    model.eval()\n",
    "    teacher.eval()\n",
    "    \n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        logits_student = student(batch)\n",
    "        logits_teacher = teacher(batch)\n",
    "\n",
    "        # distillation loss + student loss\n",
    "        probs_student = F.log_softmax(logits_student / T, dim=-1)\n",
    "        probs_teacher = F.log_softmax(logits_teacher / T, dim=-1)\n",
    "        probs = F.softmax(logits_student, dim=-1)\n",
    "        loss = nn.KLDivLoss()(probs_student, probs_teacher) * (T ** 2) * a + F.cross_entropy(logits_student, labels) * (1 - a)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "CleyHrInxZur"
   },
   "outputs": [],
   "source": [
    "sopt = torch.optim.Adam(\n",
    "    student.parameters(),\n",
    "    lr=sconfig.learning_rate,\n",
    "    weight_decay=sconfig.weight_decay\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "MsY9uiXqxZ1X",
    "outputId": "f31474dd-eef8-49e8-9fb6-7b2ad027716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student | Elapsed time : 1155.09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 197/405 [00:15<00:16, 12.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-acd11cfb1f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStudentConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdkd_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmelspec_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         au_fa_fr = dkd_validation(teacher, student, val_loader,\n",
      "\u001b[0;32m<ipython-input-40-ee8b29443410>\u001b[0m in \u001b[0;36mdkd_train_epoch\u001b[0;34m(teacher, student, opt, loader, log_melspec, device, T, a)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "seed_all(115)\n",
    "\n",
    "timer = Timer('student')\n",
    "for n in range(StudentConfig.num_epochs):\n",
    "    with timer:\n",
    "        dkd_train_epoch(teacher, student, sopt, train_loader, melspec_train, sconfig.device, sconfig.T, sconfig.a)\n",
    "\n",
    "        au_fa_fr = dkd_validation(teacher, student, val_loader,\n",
    "                          melspec_val, sconfig.device, sconfig.T, sconfig.a)\n",
    "        history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"{timer.name.capitalize()} | Elapsed time : {timer.total_time:.2f}\")\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.savefig('dkd_student.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)\n",
    "    if au_fa_fr < 5e-5 * 1.1:\n",
    "        print('The student reached the baseline')\n",
    "        torch.save(student, 'student_model.pth')\n",
    "        torch.save(student.state_dict(), 'student_model.pt')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hinIFRQbI1K",
    "outputId": "086edf30-9ac0-4a8c-9ca3-a9e1fd6dc52b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'val_metric': [0.0006238712943207893,\n",
       "              0.00035696079365995815,\n",
       "              0.0002532090114145758,\n",
       "              0.0002644876763428959,\n",
       "              0.00017560105512208783,\n",
       "              0.0001406610640346201,\n",
       "              0.0001502688156402261,\n",
       "              0.00012331340321629927,\n",
       "              9.676378402788874e-05,\n",
       "              8.313390535260672e-05,\n",
       "              7.846728314416953e-05,\n",
       "              9.956853139101595e-05,\n",
       "              9.003537413017399e-05,\n",
       "              9.989077896039652e-05,\n",
       "              7.519706706971483e-05,\n",
       "              8.674427163918537e-05,\n",
       "              8.888662122080807e-05,\n",
       "              7.759602119732576e-05,\n",
       "              6.982030669912417e-05,\n",
       "              6.43659682099789e-05,\n",
       "              7.559092521006886e-05,\n",
       "              7.684411020210443e-05,\n",
       "              6.159702613233843e-05,\n",
       "              6.37871160946101e-05,\n",
       "              8.099752331856514e-05,\n",
       "              7.504191083260566e-05,\n",
       "              6.526110034714716e-05]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZL2K1b1irnk"
   },
   "source": [
    "## FLOPs/MACs estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEz4u-BPbMVk",
    "outputId": "f24f5280-0a49-4d2a-dc68-054c535e9ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from thop) (1.12.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->thop) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7KOJipUbOfU",
    "outputId": "03072827-33da-4966-d4f4-adb0122fb607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "(1949056.0, 70443.0)\n",
      "\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "(189104.0, 4737.0)\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "list_audio = [train_set[0]['wav'], train_set[1]['wav']]\n",
    "audio = torch.cat(list_audio)\n",
    "mel = melspec_train(audio.unsqueeze(0).to(tconfig.device))\n",
    "\n",
    "print(profile(teacher, (mel, ) ))\n",
    "print('')\n",
    "print(profile(student, (mel, ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jx9aLj3sbSFV",
    "outputId": "1bc72f46-1790-443d-cc34-97a5e161a0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.30679414502073 = teacher macs / student macs\n",
      "14.870804306523116 = teacher params / student params\n"
     ]
    }
   ],
   "source": [
    "print(1949056.0 / 189104.0, \"= teacher macs / student macs\")\n",
    "print(70443.0 / 4737.0, \"= teacher params / student params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lV7JP38jFte"
   },
   "source": [
    "## Memory estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxLPu5YkbXFj",
    "outputId": "c7171a52-8331-4f71-ef60-4c38c3be5ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.770565605304084 = teacher memory / student memory\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "def get_size_in_megabytes(model):\n",
    "    # https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html#look-at-model-size\n",
    "    with tempfile.TemporaryFile() as f:\n",
    "        torch.save(model.state_dict(), f)\n",
    "        size = f.tell() / 2**20\n",
    "    return size\n",
    "\n",
    "print(get_size_in_megabytes(teacher) / get_size_in_megabytes(student), \"= teacher memory / student memory\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
