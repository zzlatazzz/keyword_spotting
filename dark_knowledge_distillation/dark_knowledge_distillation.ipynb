{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhrn5O-qUYZ"
      },
      "source": [
        "# Import and misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "meO-Mp9jiAFC"
      },
      "outputs": [],
      "source": [
        "# Instal latest torch and torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bbUpoArCqUYa"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union, List, Callable, Optional\n",
        "from tqdm import tqdm\n",
        "from itertools import islice\n",
        "import pathlib\n",
        "import dataclasses\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchaudio\n",
        "from IPython import display as display_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812GwLfqqUYf"
      },
      "source": [
        "# Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8PdhApeEh9pH"
      },
      "outputs": [],
      "source": [
        "@dataclasses.dataclass\n",
        "class TaskConfig:\n",
        "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 3e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    num_epochs: int = 20\n",
        "    n_mels: int = 40\n",
        "    cnn_out_channels: int = 8\n",
        "    kernel_size: Tuple[int, int] = (5, 20)\n",
        "    stride: Tuple[int, int] = (2, 8)\n",
        "    hidden_size: int = 64\n",
        "    gru_num_layers: int = 2\n",
        "    bidirectional: bool = False\n",
        "    num_classes: int = 2\n",
        "    sample_rate: int = 16000\n",
        "    device: torch.device = torch.device(\n",
        "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA1gPmE1h9pI"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y2N8zcx9MF1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f287761-e809-4518-91db-39366bd0ea53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-30 22:15:44--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.197.128, 2607:f8b0:400e:c03::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.197.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G   145MB/s    in 11s     \n",
            "\n",
            "2022-10-30 22:15:55 (133 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
        "!mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "12wBTK0mNUsG"
      },
      "outputs": [],
      "source": [
        "class SpeechCommandDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        transform: Optional[Callable] = None,\n",
        "        path2dir: str = None,\n",
        "        keywords: Union[str, List[str]] = None,\n",
        "        csv: Optional[pd.DataFrame] = None\n",
        "    ):        \n",
        "        self.transform = transform\n",
        "\n",
        "        if csv is None:\n",
        "            path2dir = pathlib.Path(path2dir)\n",
        "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
        "            \n",
        "            all_keywords = [\n",
        "                p.stem for p in path2dir.glob('*')\n",
        "                if p.is_dir() and not p.stem.startswith('_')\n",
        "            ]\n",
        "\n",
        "            triplets = []\n",
        "            for keyword in all_keywords:\n",
        "                paths = (path2dir / keyword).rglob('*.wav')\n",
        "                if keyword in keywords:\n",
        "                    for path2wav in paths:\n",
        "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
        "                else:\n",
        "                    for path2wav in paths:\n",
        "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
        "            \n",
        "            self.csv = pd.DataFrame(\n",
        "                triplets,\n",
        "                columns=['path', 'keyword', 'label']\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.csv = csv\n",
        "    \n",
        "    def __getitem__(self, index: int):\n",
        "        instance = self.csv.iloc[index]\n",
        "\n",
        "        path2wav = instance['path']\n",
        "        wav, sr = torchaudio.load(path2wav)\n",
        "        wav = wav.sum(dim=0)\n",
        "        \n",
        "        if self.transform:\n",
        "            wav = self.transform(wav)\n",
        "\n",
        "        return {\n",
        "            'wav': wav,\n",
        "            'keywors': instance['keyword'],\n",
        "            'label': instance['label']\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-1rVkT81Pk90"
      },
      "outputs": [],
      "source": [
        "dataset = SpeechCommandDataset(\n",
        "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DFwhAXdfQLIA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "51c5a369-8380-4e2c-c53c-f881dd15dd6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              path keyword  label\n",
              "23154  speech_commands/right/03c96658_nohash_0.wav   right      0\n",
              "40942   speech_commands/down/cdbd6969_nohash_1.wav    down      0\n",
              "53823     speech_commands/up/7f74626f_nohash_3.wav      up      0\n",
              "62722     speech_commands/no/e57d35bc_nohash_2.wav      no      0\n",
              "4740    speech_commands/bird/179a61b7_nohash_0.wav    bird      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0666b88b-b6e8-42f3-967a-18c8191bd77e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>keyword</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23154</th>\n",
              "      <td>speech_commands/right/03c96658_nohash_0.wav</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40942</th>\n",
              "      <td>speech_commands/down/cdbd6969_nohash_1.wav</td>\n",
              "      <td>down</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53823</th>\n",
              "      <td>speech_commands/up/7f74626f_nohash_3.wav</td>\n",
              "      <td>up</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62722</th>\n",
              "      <td>speech_commands/no/e57d35bc_nohash_2.wav</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4740</th>\n",
              "      <td>speech_commands/bird/179a61b7_nohash_0.wav</td>\n",
              "      <td>bird</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0666b88b-b6e8-42f3-967a-18c8191bd77e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0666b88b-b6e8-42f3-967a-18c8191bd77e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0666b88b-b6e8-42f3-967a-18c8191bd77e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset.csv.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUxfDJw1qUYi"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dkmkxPWQqUYe"
      },
      "outputs": [],
      "source": [
        "class AugsCreation:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.background_noises = [\n",
        "            'speech_commands/_background_noise_/white_noise.wav',\n",
        "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
        "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
        "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
        "            'speech_commands/_background_noise_/pink_noise.wav',\n",
        "            'speech_commands/_background_noise_/running_tap.wav'\n",
        "        ]\n",
        "\n",
        "        self.noises = [\n",
        "            torchaudio.load(p)[0].squeeze()\n",
        "            for p in self.background_noises\n",
        "        ]\n",
        "\n",
        "    def add_rand_noise(self, audio):\n",
        "\n",
        "        # randomly choose noise\n",
        "        noise_num = torch.randint(low=0, high=len(\n",
        "            self.background_noises), size=(1,)).item()\n",
        "        noise = self.noises[noise_num]\n",
        "\n",
        "        noise_level = torch.Tensor([1])  # [0, 40]\n",
        "\n",
        "        noise_energy = torch.norm(noise)\n",
        "        audio_energy = torch.norm(audio)\n",
        "        alpha = (audio_energy / noise_energy) * \\\n",
        "            torch.pow(10, -noise_level / 20)\n",
        "\n",
        "        start = torch.randint(\n",
        "            low=0,\n",
        "            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n",
        "            size=(1,)\n",
        "        ).item()\n",
        "        noise_sample = noise[start: start + audio.size(0)]\n",
        "\n",
        "        audio_new = audio + alpha * noise_sample\n",
        "        audio_new.clamp_(-1, 1)\n",
        "        return audio_new\n",
        "\n",
        "    def __call__(self, wav):\n",
        "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
        "        augs = [\n",
        "            lambda x: x,\n",
        "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
        "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
        "            lambda x: self.add_rand_noise(x)\n",
        "        ]\n",
        "\n",
        "        return augs[aug_num](wav)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ClWThxyYh9pM"
      },
      "outputs": [],
      "source": [
        "indexes = torch.randperm(len(dataset))\n",
        "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
        "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
        "\n",
        "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
        "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PDPLht5fqUYe"
      },
      "outputs": [],
      "source": [
        "# Sample is a dict of utt, word and label\n",
        "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
        "val_set = SpeechCommandDataset(csv=val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mmrJd8WIhkLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75622a1c-e017-4483-8542-7ecbf4117fb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'wav': tensor([-0.0016, -0.0017, -0.0017,  ..., -0.0017, -0.0024, -0.0026]),\n",
              " 'keywors': 'go',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_set[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbPDqd6qUYj"
      },
      "source": [
        "### Sampler for oversampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rfnjRKo2qUYj"
      },
      "outputs": [],
      "source": [
        "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
        "\n",
        "def get_sampler(target):\n",
        "    class_sample_count = np.array(\n",
        "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in target])\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    samples_weigth = samples_weight.float()\n",
        "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "    return sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UM8gLmHeqUYj"
      },
      "outputs": [],
      "source": [
        "train_sampler = get_sampler(train_set.csv['label'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lyBqbxp0h9pO"
      },
      "outputs": [],
      "source": [
        "class Collator:\n",
        "    \n",
        "    def __call__(self, data):\n",
        "        wavs = []\n",
        "        labels = []    \n",
        "\n",
        "        for el in data:\n",
        "            wavs.append(el['wav'])\n",
        "            labels.append(el['label'])\n",
        "\n",
        "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
        "        wavs = pad_sequence(wavs, batch_first=True)    \n",
        "        labels = torch.Tensor(labels).long()\n",
        "        return wavs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8G9xPRVqUYk"
      },
      "source": [
        "###  Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6wGBMcQiqUYk"
      },
      "outputs": [],
      "source": [
        "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
        "                          shuffle=False, collate_fn=Collator(),\n",
        "                          sampler=train_sampler,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
        "                        shuffle=False, collate_fn=Collator(),\n",
        "                        num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTlsn6cpqUYk"
      },
      "source": [
        "### Creating MelSpecs on GPU for speeeed: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pRXMt6it56fW"
      },
      "outputs": [],
      "source": [
        "class LogMelspec:\n",
        "\n",
        "    def __init__(self, is_train, config):\n",
        "        # with augmentations\n",
        "        if is_train:\n",
        "            self.melspec = nn.Sequential(\n",
        "                torchaudio.transforms.MelSpectrogram(\n",
        "                    sample_rate=config.sample_rate,\n",
        "                    n_fft=400,\n",
        "                    win_length=400,\n",
        "                    hop_length=160,\n",
        "                    n_mels=config.n_mels\n",
        "                ),\n",
        "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
        "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
        "            ).to(config.device)\n",
        "\n",
        "        # no augmentations\n",
        "        else:\n",
        "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
        "                sample_rate=config.sample_rate,\n",
        "                n_fft=400,\n",
        "                win_length=400,\n",
        "                hop_length=160,\n",
        "                n_mels=config.n_mels\n",
        "            ).to(config.device)\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # already on device\n",
        "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pqkz4_gn8BiF"
      },
      "outputs": [],
      "source": [
        "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
        "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoAxmihY8yxr"
      },
      "source": [
        "### Quality measurment functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "euwD1UyuqUYk"
      },
      "outputs": [],
      "source": [
        "# FA - true: 0, model: 1\n",
        "# FR - true: 1, model: 0\n",
        "\n",
        "def count_FA_FR(preds, labels):\n",
        "    FA = torch.sum(preds[labels == 0])\n",
        "    FR = torch.sum(labels[preds == 0])\n",
        "    \n",
        "    # torch.numel - returns total number of elements in tensor\n",
        "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YHBUrkT1qUYk"
      },
      "outputs": [],
      "source": [
        "def get_au_fa_fr(probs, labels):\n",
        "    sorted_probs, _ = torch.sort(probs)\n",
        "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "        \n",
        "    FAs, FRs = [], []\n",
        "    for prob in sorted_probs:\n",
        "        preds = (probs >= prob) * 1\n",
        "        FA, FR = count_FA_FR(preds, labels)        \n",
        "        FAs.append(FA)\n",
        "        FRs.append(FR)\n",
        "    # plt.plot(FAs, FRs)\n",
        "    # plt.show()\n",
        "\n",
        "    # ~ area under curve using trapezoidal rule\n",
        "    return -np.trapz(FRs, x=FAs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcEP5cEZqUYl"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2cP_pFIsy5p2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1aa72f-f840-49a8-8335-3e068e68d6e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
              "    (1): Flatten(start_dim=1, end_dim=2)\n",
              "  )\n",
              "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (attention): Attention(\n",
              "    (energy): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.energy = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        energy = self.energy(input)\n",
        "        alpha = torch.softmax(energy, dim=-2)\n",
        "        return (input * alpha).sum(dim=-2)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TaskConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1, out_channels=config.cnn_out_channels,\n",
        "                kernel_size=config.kernel_size, stride=config.stride\n",
        "            ),\n",
        "            nn.Flatten(start_dim=1, end_dim=2),\n",
        "        )\n",
        "\n",
        "        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n",
        "            config.stride[0] + 1\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.conv_out_frequency * config.cnn_out_channels,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.gru_num_layers,\n",
        "            dropout=0.1,\n",
        "            bidirectional=config.bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.attention = Attention(config.hidden_size)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        input = input.unsqueeze(dim=1)\n",
        "        conv_output = self.conv(input).transpose(-1, -2)\n",
        "        gru_output, _ = self.gru(conv_output)\n",
        "        contex_vector = self.attention(gru_output)\n",
        "        output = self.classifier(contex_vector)\n",
        "        return output\n",
        "\n",
        "config = TaskConfig()\n",
        "model = CRNN(config)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DmmSFvWaqUYn"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, opt, loader, log_melspec, device):\n",
        "    model.train()\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # run model # with autocast():\n",
        "        logits = model(batch)\n",
        "        # we need probabilities so we use softmax & CE separately\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UIeRbn4tqUYo"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def validation(model, loader, log_melspec, device):\n",
        "    model.eval()\n",
        "\n",
        "    val_losses, accs, FAs, FRs = [], [], [], []\n",
        "    all_probs, all_labels = [], []\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        output = model(batch)\n",
        "        # we need probabilities so we use softmax & CE separately\n",
        "        probs = F.softmax(output, dim=-1)\n",
        "        loss = F.cross_entropy(output, labels)\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        all_probs.append(probs[:, 1].cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "        val_losses.append(loss.item())\n",
        "        accs.append(\n",
        "            torch.sum(argmax_probs == labels).item() /  # ???\n",
        "            torch.numel(argmax_probs)\n",
        "        )\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        FAs.append(FA)\n",
        "        FRs.append(FR)\n",
        "\n",
        "    # area under FA/FR curve for whole loader\n",
        "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
        "    return au_fa_fr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSNW-nZCJ4Q0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PpyvKwp0k3IU"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = defaultdict(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Q8sVpHNoocgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93424caa-5811-491a-8b90-6cdd6927f2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRNN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
            "    (1): Flatten(start_dim=1, end_dim=2)\n",
            "  )\n",
            "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (attention): Attention(\n",
            "    (energy): Sequential(\n",
            "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "config = TaskConfig()\n",
        "model = CRNN(config).to(torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "print(model)\n",
        "\n",
        "opt = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config.learning_rate,\n",
        "    weight_decay=config.weight_decay\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zedXm9dmINAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2160b52-fc0d-4c9c-f0cd-b0ff237e4c4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70443"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vt2kjqC-IobK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "32oooz4lqUYo",
        "outputId": "cdf1e7a1-d4f4-4e51-984a-77a813628f5a",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "END OF EPOCH 19\n"
          ]
        }
      ],
      "source": [
        "# TRAIN\n",
        "seed_all(112)\n",
        "for n in range(TaskConfig.num_epochs):\n",
        "\n",
        "    train_epoch(model, opt, train_loader, melspec_train, config.device)\n",
        "\n",
        "    au_fa_fr = validation(model, val_loader,\n",
        "                          melspec_val, config.device)\n",
        "    history['val_metric'].append(au_fa_fr)\n",
        "\n",
        "    clear_output()\n",
        "    plt.plot(history['val_metric'])\n",
        "    plt.ylabel('Metric')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    print('END OF EPOCH', n)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E05Jy3459RF4",
        "outputId": "2168180a-1b90-4ded-eca4-bd84cf9867cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'val_metric': [0.00044027969298757956,\n",
              "              0.00019083918787048213,\n",
              "              0.00017144167445804596,\n",
              "              0.0001327361608468905,\n",
              "              0.00011620008649960218,\n",
              "              7.827035407399252e-05,\n",
              "              5.647090276015486e-05,\n",
              "              4.9291943020065424e-05,\n",
              "              4.030481636289611e-05,\n",
              "              4.6087369969003066e-05,\n",
              "              4.049577788549201e-05,\n",
              "              4.408824152932729e-05,\n",
              "              5.1804280551717675e-05,\n",
              "              4.43776675870117e-05,\n",
              "              4.0943343954076135e-05,\n",
              "              3.877712418212896e-05,\n",
              "              3.874131889664222e-05,\n",
              "              4.202943761384029e-05,\n",
              "              3.40925993309484e-05,\n",
              "              3.845487661274838e-05]})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WBkTUHZcVugz"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'teacher_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tconfig = TaskConfig()\n",
        "teacher = torch.load('teacher_model.pth').to(tconfig.device)\n",
        "teacher.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmkSRvg36KdC",
        "outputId": "4c88e56f-0855-48d7-9400-9080a2eda502"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
              "    (1): Flatten(start_dim=1, end_dim=2)\n",
              "  )\n",
              "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (attention): Attention(\n",
              "    (energy): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StudentConfig"
      ],
      "metadata": {
        "id": "MPMgfwowi3X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Уменьшаем параметры у студента\n",
        "# После решетки указаны старые параметры\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class StudentConfig:\n",
        "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 1e-3 # 3e-4\n",
        "    weight_decay: float = 1e-5 # 1e-5\n",
        "    num_epochs: int = 40 # 20\n",
        "    n_mels: int = 40\n",
        "    cnn_out_channels: int = 2 # 8\n",
        "    kernel_size: Tuple[int, int] = (5, 20) # (5, 20)\n",
        "    stride: Tuple[int, int] = (2, 8) # (2, 8)\n",
        "    hidden_size: int = 22 # 64\n",
        "    gru_num_layers: int = 1 # 2\n",
        "    bidirectional: bool = False\n",
        "    num_classes: int = 2\n",
        "    sample_rate: int = 16000\n",
        "    device: torch.device = torch.device(\n",
        "        'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    T: float = 10\n",
        "    a: float = 0.3\n",
        "    "
      ],
      "metadata": {
        "id": "i-7dPBrq6KfH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sconfig = StudentConfig()\n",
        "student = CRNN(sconfig).to(sconfig.device)"
      ],
      "metadata": {
        "id": "QzVrM_1w6Kjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48f5a19-54ec-441f-9d06-4238da93efe1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FLOPs/MACs estimation"
      ],
      "metadata": {
        "id": "UZL2K1b1irnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiZD0qFi7GZP",
        "outputId": "1d6b8cca-6f24-48e9-8471-9a503b9d6e86"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from thop) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->thop) (4.1.1)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile\n",
        "\n",
        "print(profile(teacher, (melspec_train(next(iter(train_loader))[0].to(tconfig.device)), ) ))\n",
        "print('')\n",
        "print(profile(student, (melspec_train(next(iter(train_loader))[0].to(sconfig.device)), ) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc5B0pQN7Ne8",
        "outputId": "f4f55ad3-50ba-46c0-861a-1d76dd61917f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "(119324672.0, 70443.0)\n",
            "\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "(11579392.0, 4737.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(119324672.0 / 11579392.0, \"= teacher macs / student macs\")\n",
        "print(70443.0 / 4737.0, \"= teacher params / student params\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VAeBf9NPXWT",
        "outputId": "2ed6b5ff-d4d7-4759-bd60-4d1914e5e2e7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.304916873010258 = teacher macs / student macs\n",
            "14.870804306523116 = teacher params / student params\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory estimation"
      ],
      "metadata": {
        "id": "8lV7JP38jFte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "def get_size_in_megabytes(model):\n",
        "    # https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html#look-at-model-size\n",
        "    with tempfile.TemporaryFile() as f:\n",
        "        torch.save(model.state_dict(), f)\n",
        "        size = f.tell() / 2**20\n",
        "    return size\n",
        "\n",
        "print(get_size_in_megabytes(teacher) / get_size_in_megabytes(student), \"= teacher memory / student memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5UDTGrujEut",
        "outputId": "f2565219-5ac8-4c7b-bf6b-13486afdb37a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.770565605304084 = teacher memory / student memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student training"
      ],
      "metadata": {
        "id": "sIQrRXlskAOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dkd_train_epoch(teacher, student, opt, loader, log_melspec, device, T, a):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        logits_student = student(batch)\n",
        "        with torch.no_grad():\n",
        "            logits_teacher = teacher(batch)\n",
        "\n",
        "        # distillation loss + student loss\n",
        "        probs_student = F.log_softmax(logits_student / T, dim=-1)\n",
        "        probs_teacher = F.log_softmax(logits_teacher / T, dim=-1)\n",
        "        probs = F.softmax(logits_student, dim=-1)\n",
        "        loss = nn.KLDivLoss()(probs_student, probs_teacher) * (T ** 2) * a + F.cross_entropy(logits_student, labels) * (1 - a)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student.parameters(), 5)\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "BvlzuXugsTZp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def dkd_validation(teacher, student, loader, log_melspec, device, T, a):\n",
        "    model.eval()\n",
        "    teacher.eval()\n",
        "    \n",
        "    val_losses, accs, FAs, FRs = [], [], [], []\n",
        "    all_probs, all_labels = [], []\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        logits_student = student(batch)\n",
        "        logits_teacher = teacher(batch)\n",
        "\n",
        "        # distillation loss + student loss\n",
        "        probs_student = F.log_softmax(logits_student / T, dim=-1)\n",
        "        probs_teacher = F.log_softmax(logits_teacher / T, dim=-1)\n",
        "        probs = F.softmax(logits_student, dim=-1)\n",
        "        loss = nn.KLDivLoss()(probs_student, probs_teacher) * (T ** 2) * a + F.cross_entropy(logits_student, labels) * (1 - a)\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        all_probs.append(probs[:, 1].cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "        val_losses.append(loss.item())\n",
        "        accs.append(\n",
        "            torch.sum(argmax_probs == labels).item() /  # ???\n",
        "            torch.numel(argmax_probs)\n",
        "        )\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        FAs.append(FA)\n",
        "        FRs.append(FR)\n",
        "\n",
        "    # area under FA/FR curve for whole loader\n",
        "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
        "    return au_fa_fr"
      ],
      "metadata": {
        "id": "dKgIipFzwDYF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sopt = torch.optim.Adam(\n",
        "    student.parameters(),\n",
        "    lr=sconfig.learning_rate,\n",
        "    weight_decay=sconfig.weight_decay\n",
        ")\n",
        "\n",
        "history = defaultdict(list)"
      ],
      "metadata": {
        "id": "CleyHrInxZur"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN\n",
        "seed_all(112)\n",
        "for n in range(StudentConfig.num_epochs):\n",
        "\n",
        "    dkd_train_epoch(teacher, student, sopt, train_loader, melspec_train, sconfig.device, sconfig.T, sconfig.a)\n",
        "\n",
        "    au_fa_fr = dkd_validation(teacher, student, val_loader,\n",
        "                          melspec_val, sconfig.device, sconfig.T, sconfig.a)\n",
        "    history['val_metric'].append(au_fa_fr)\n",
        "\n",
        "    clear_output()\n",
        "    plt.plot(history['val_metric'])\n",
        "    plt.ylabel('Metric')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    print('END OF EPOCH', n)\n",
        "    if au_fa_fr < 5e-5 * 1.1:\n",
        "        print('The student reached the baseline')\n",
        "        torch.save(model, 'student_model.pth')\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "MsY9uiXqxZ1X",
        "outputId": "d77d6e83-1030-4503-8877-479510979cf7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "END OF EPOCH 31\n",
            "The student reached the baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "qfl6OkIVD3Q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f6a567-261c-4ee6-8fda-667ea69262ff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'val_metric': [0.0008547199049489022,\n",
              "              0.0006915850567237776,\n",
              "              0.00045939374788991243,\n",
              "              0.0003403739951582303,\n",
              "              0.0002583709400722461,\n",
              "              0.00022412318450418855,\n",
              "              0.0002018343942886989,\n",
              "              0.00018639336492254645,\n",
              "              0.00015981689177002088,\n",
              "              0.0001599959181974545,\n",
              "              0.0001438357993477769,\n",
              "              0.0001193091787893666,\n",
              "              0.00010897637015265434,\n",
              "              0.00010409790000508733,\n",
              "              0.00010302970898806654,\n",
              "              9.680257308716602e-05,\n",
              "              8.296681402033531e-05,\n",
              "              9.04083458539941e-05,\n",
              "              9.024125452172269e-05,\n",
              "              7.461821495434603e-05,\n",
              "              8.643395916496703e-05,\n",
              "              9.629831531656125e-05,\n",
              "              7.357986167523084e-05,\n",
              "              8.036496327496624e-05,\n",
              "              7.324567901068803e-05,\n",
              "              6.594140077139504e-05,\n",
              "              6.994562519832771e-05,\n",
              "              7.979804625475969e-05,\n",
              "              8.254311814207567e-05,\n",
              "              6.791665902074633e-05,\n",
              "              7.363356960346095e-05,\n",
              "              5.25263538090334e-05]})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}